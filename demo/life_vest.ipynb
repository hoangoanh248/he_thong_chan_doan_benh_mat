{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"life_vest.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"q1uzRPtxmYbj","colab_type":"text"},"source":["# Install dependencies"]},{"cell_type":"code","metadata":{"id":"sqUenHi1ZlQv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1597889133653,"user_tz":-420,"elapsed":23598,"user":{"displayName":"Oanh Pham","photoUrl":"","userId":"07064024230159202916"}},"outputId":"48edc5e5-c208-4538-a1a4-6188b8a6bad6"},"source":["!pip install -q streamlit"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 7.2MB 4.5MB/s \n","\u001b[K     |████████████████████████████████| 112kB 42.9MB/s \n","\u001b[K     |████████████████████████████████| 4.4MB 39.8MB/s \n","\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n","\u001b[K     |████████████████████████████████| 122kB 42.8MB/s \n","\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dalaf_IvbFzl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1597889139088,"user_tz":-420,"elapsed":28592,"user":{"displayName":"Oanh Pham","photoUrl":"","userId":"07064024230159202916"}},"outputId":"1ff304bb-6798-4459-c29c-822d1a5c4b6c"},"source":["!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -qq ngrok-stable-linux-amd64.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-08-20 02:05:35--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","Resolving bin.equinox.io (bin.equinox.io)... 54.145.36.98, 3.225.89.236, 34.206.18.248, ...\n","Connecting to bin.equinox.io (bin.equinox.io)|54.145.36.98|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 13773305 (13M) [application/octet-stream]\n","Saving to: ‘ngrok-stable-linux-amd64.zip’\n","\n","ngrok-stable-linux- 100%[===================>]  13.13M  14.2MB/s    in 0.9s    \n","\n","2020-08-20 02:05:36 (14.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4rFORK3Yety7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"ok","timestamp":1597889151776,"user_tz":-420,"elapsed":38602,"user":{"displayName":"Oanh Pham","photoUrl":"","userId":"07064024230159202916"}},"outputId":"69abe5b8-30d7-4f9a-ff28-faac5cf11abb"},"source":["!pip install efficientnet_pytorch\n","!pip install bunch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting efficientnet_pytorch\n","  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=9918a318f1e95c8cb718b2e8bea34288615cd20313e51ef866c3612d51c2befe\n","  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.6.3\n","Collecting bunch\n","  Downloading https://files.pythonhosted.org/packages/ef/bf/a4cf1779a4ffb4f610903fa08e15d1f4a8a2f4e3353a02afbe097c5bf4a8/bunch-1.0.1.tar.gz\n","Building wheels for collected packages: bunch\n","  Building wheel for bunch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bunch: filename=bunch-1.0.1-cp36-none-any.whl size=7076 sha256=d3ff2ef538e7f850901ca46b93243a159ad11cc579ca1f0d686fe55faebf5a8f\n","  Stored in directory: /root/.cache/pip/wheels/56/0f/19/fbbf81e5764e6d8b74501c4357a88c14c94466ec777c03734c\n","Successfully built bunch\n","Installing collected packages: bunch\n","Successfully installed bunch-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gvy3Cyr1fJOB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1597889157882,"user_tz":-420,"elapsed":44166,"user":{"displayName":"Oanh Pham","photoUrl":"","userId":"07064024230159202916"}},"outputId":"9ca5c245-d4b3-4de1-9aa7-3a4665c2661a"},"source":["!gdown --id '1NeItjRYE6vXm1XXw750SeGf_mxgO7_59'\n","!unzip -qq configs.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1NeItjRYE6vXm1XXw750SeGf_mxgO7_59\n","To: /content/configs.zip\n","6.56MB [00:00, 39.8MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KEY7R8CI9G6A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1597889168163,"user_tz":-420,"elapsed":53873,"user":{"displayName":"Oanh Pham","photoUrl":"","userId":"07064024230159202916"}},"outputId":"9a7687a2-2e5a-4ed9-f8c3-bc1121e3147e"},"source":["!gdown --id '1mwfsbIFWcvIpJS-Mes049kv-TwUztf30'\n","!unzip -qq model.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1mwfsbIFWcvIpJS-Mes049kv-TwUztf30\n","To: /content/model.zip\n","160MB [00:01, 90.5MB/s]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YP_ca5YQmfTV","colab_type":"text"},"source":["# Put your code inside `util` variable\n","Complete the code in your local and then put it in here."]},{"cell_type":"code","metadata":{"id":"uZaQWcPWhMH1","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Utilization\n","#@markdown Run this cell to create utils.py.\n","#@markdown Add your code to 2 functions called `create_clahe` and `create_vessel`.\n","\n","util = '''\n","from efficientnet_pytorch import EfficientNet\n","from albumentations import Compose, Resize, Normalize\n","import cv2\n","import torch.nn as nn\n","import torch\n","import numpy as np\n","from keras.models import model_from_json\n","from configs.utils.img_utils import get_test_patches,pred_to_patches,recompone_overlap\n","from configs.utils.config_utils import process_config\n","\n","\n","config = process_config(\"./configs/segmention_config.json\")\n","vessel_model = model_from_json(open(\"./configs/VesselNet_architecture.json\").read())\n","vessel_model.load_weights(\"./configs/VesselNet_best_weights.h5\")\n","\n","class Cooker(object):\n","  def __init__(self, resolution=240, p=1, tol=7):\n","    self.alb_ingstance = Compose([Resize(resolution,resolution),Normalize()], p=1)\n","    self.tol = tol\n","\n","  def crop_image_from_gray(self, img, tol=None):\n","    tol = tol if tol else self.tol\n","\n","    if img.ndim == 2:\n","      mask = img > tol\n","      return img[np.ix_(mask.any(1), mask.any(0))]\n","    elif img.ndim == 3:\n","      gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","      mask = gray_img > tol\n","\n","      check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n","      if (check_shape == 0):  # image is too dark so that we crop out everything,\n","        return img  # return original image\n","      else:\n","        img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n","        img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n","        img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n","        img = np.stack([img1, img2, img3], axis=-1)\n","      return img\n","\n","  def agu_val(self, img):\n","    return self.alb_ingstance(image=img)['image']\n","\n","  def __call__(self, img):\n","    if type(img) == list:\n","      return [self(image) for image in img]\n","    # img = self.crop_image_from_gray(img)\n","    img = self.agu_val(img)\n","    return torch.from_numpy(img.transpose((2, 0, 1))).float().unsqueeze(0)  \n","\n","class NeuralNet(nn.Module):\n","  def __init__(self):\n","    super(NeuralNet, self).__init__()\n","    self.modelA = EfficientNet.from_pretrained('efficientnet-b3', num_classes=8)\n","    self.modelB = EfficientNet.from_pretrained('efficientnet-b3', num_classes=8)\n","\n","    self.drop = nn.Dropout(0.3)\n","    self.out2 = nn.Linear(1536, 8)\n","    self.load_state()\n","\n","  def load_state(self,\n","                 clahe_path='./model/clahe.pth',\n","                 vessel_path='./model/vessel.pth',\n","                 combine_path='./model/final.pth'\n","                 ):\n","    self.modelA.load_state_dict(\n","      torch.load(clahe_path)['model_state_dict']\n","    )\n","    print(\"Loaded weights from\", clahe_path)\n","\n","    self.modelB.load_state_dict(\n","      torch.load(vessel_path)['model_state_dict']\n","    )\n","    print(\"Loaded weights from\", vessel_path)\n","    \n","    self.load_state_dict(torch.load(combine_path))\n","    print(\"Loaded weights from\", combine_path)\n","\n","  def forward(self, x1, x2):\n","    x1 = self.modelA.extract_features(x1)\n","    x2 = self.modelB.extract_features(x2)\n","    \n","    x1 = nn.AdaptiveAvgPool2d((1, 1))(x1)\n","    x2 = nn.AdaptiveAvgPool2d((1, 1))(x2)\n","    x1 = x1.view(1,1536)\n","    x2 = x2.view(1,1536)\n","    x = x1+x2    \n","    sigmoid = torch.sigmoid(x)\n","    multi = torch.mul(sigmoid,x2)\n","    x = multi + x1\n","    x = self.drop(x)\n","    x = x.flatten()\n","    x = self.out2(x)\n","    return torch.sigmoid(x)\n","\n","def predict(model, l_clahe, l_vessel, r_clahe=None, r_vessel=None, device='cuda'):\n","  model.to(device)\n","  l_prediction = model(l_clahe.to(device), l_vessel.to(device)).cpu().detach().numpy()\n","  \n","  if r_clahe is not None and r_vessel is not None:\n","    r_prediction = model(r_clahe.to(device), r_vessel.to(device)).cpu().detach().numpy()\n","    return np.where(l_prediction > r_prediction, l_prediction, r_prediction)\n","  return l_prediction\n","\n","def crop_image(img, tol=7):\n","    if img.ndim == 2:\n","        mask = img > tol\n","        return img[np.ix_(mask.any(1), mask.any(0))]\n","    elif img.ndim == 3:\n","        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","        mask = gray_img > tol\n","\n","        check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n","        if (check_shape == 0):  # image is too dark so that we crop out everything,\n","            return img  # return original image\n","        else:\n","            img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n","            img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n","            img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n","            img = np.stack([img1, img2, img3], axis=-1)\n","        return img\n","        \n","def create_clahe(img):\n","    \"\"\"Function to create and return clahe image\n","\n","        Parameter\n","        ---------\n","        img : Image or numpy.array\n","            A PIL Image object or image in numpy.array\n","\n","        Return\n","        ------\n","        A PIL Image object or numpy.array image\n","    \"\"\"\n","    dim = (240, 240)\n","    img = crop_image(img)\n","    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n","\n","    clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(4, 4))\n","    for i in range(3):\n","        img[:, :, i] = clahe.apply((img[:, :, i]))\n","    print('clahe:',img.shape)\n","    return img\n","\n","def create_vessel(img, model=vessel_model):\n","    \"\"\"Function to create and return vessel image\n","\n","        Parameter\n","        ---------\n","        img : Image or numpy.array\n","            A PIL Image object or image in numpy.array\n","\n","        Return\n","        ------\n","        A PIL Image object or numpy.array image\n","    \"\"\"\n","    dim = (240, 240)\n","    img = crop_image(img)\n","    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n","\n","    orgImg_temp=img\n","    orgImg=orgImg_temp[:,:,1]*0.75+orgImg_temp[:,:,0]*0.25\n","    height,width=orgImg.shape[:2]\n","    orgImg = np.reshape(orgImg, (height,width,1))\n","    patches_pred,new_height,new_width,adjustImg=get_test_patches(orgImg,config)\n","    predictions = model.predict(patches_pred, batch_size=32, verbose=1)\n","    pred_patches=pred_to_patches(predictions,config)\n","    pred_imgs=recompone_overlap(pred_patches,config,new_height,new_width)\n","    pred_imgs=pred_imgs[:,0:height,0:width,:]\n","    adjustImg=adjustImg[0,0:height,0:width,:]\n","    print(adjustImg.shape)\n","    probResult=pred_imgs[0,:,:,0]\n","    img = (probResult*255).astype(np.uint8)\n","    img = np.stack((img,)*3, axis=-1)\n","    return img\n","'''\n","\n","with open(\"utils.py\", 'w') as f:\n","  f.write(util)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ij5Tb2FTl1nI","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Main streamlit app\n","#@markdown You don't need to edit this file any more.\n","code = '''\n","import numpy as np\n","import pandas as pd\n","import streamlit as st\n","import cv2\n","import matplotlib.pyplot as plt\n","from utils import NeuralNet, Cooker, predict, create_clahe, create_vessel\n","\n","\n","##############################\n","# code start from here\n","# some configs\n","st.set_option('deprecation.showfileUploaderEncoding', False)\n","\n","# cpu or cuda\n","device = 'cuda'\n","\n","# label of diseases\n","labels = [\n","    \"Normal\",\n","    \"Diabetes\",\n","    \"Glaucoma\",\n","    \"Cataract\",\n","    \"AMD\",\n","    \"Hypertension\",\n","    \"Myopia\",\n","    \"Other diseases/abnormalities\"\n","]\n","\n","#init fortune teller\n","@st.cache\n","def func(Cooker, NeuralNet):\n","  cooker = Cooker()\n","  x_model = NeuralNet()\n","  x_model.eval()\n","  return cooker, x_model\n","  \n","cooker, x_model = func(Cooker, NeuralNet)\n","\n","left_img = left_fundus = None\n","right_img = right_fundus = None\n","fundus_imgs = []\n","fundus_caps = []\n","fundus_imgs_after_l = []\n","fundus_caps_after_l = []\n","fundus_imgs_after_r = []\n","fundus_caps_after_r = []\n","model_input_holder = {\n","    'left': None,\n","    'right': None\n","}\n","\n","st.sidebar.header('Choose fundus images of patient.')\n","left_fundus_img = st.sidebar.file_uploader(\"Choose left fundus image\", type='jpg')\n","right_fundus_img = st.sidebar.file_uploader(\"Choose right fundus image\", type='jpg')\n","\n","if left_fundus_img:\n","    left_img = np.frombuffer(left_fundus_img.read(), np.uint8)\n","    left_img = cv2.imdecode(left_img, cv2.IMREAD_COLOR)\n","    fundus_imgs.append(left_img)\n","    fundus_caps.append(\"Left fundus\")\n","    left_fundus = True\n","\n","if right_fundus_img:\n","    right_img = np.frombuffer(right_fundus_img.read(), np.uint8)\n","    right_img = cv2.imdecode(right_img, cv2.IMREAD_COLOR)\n","    fundus_imgs.append(right_img)\n","    fundus_caps.append(\"Right fundus\")\n","    right_fundus = True\n","\n","if left_fundus or right_fundus:\n","    \"## Fundus images of patient\"\n","    st.image(fundus_imgs, caption=fundus_caps, width=330, channels='BGR')\n","\n","st.sidebar.header('Preprocess images by creating clahe and vessel images from input.')\n","\n","pre_process = st.sidebar.button(\"Create CLAHE & Vessel images\")\n","\n","if pre_process and (left_fundus or right_fundus):\n","    \"## Process left fundus image:\"\n","    if left_fundus:\n","        l_clahe = create_clahe(left_img)\n","        fundus_imgs_after_l.append(l_clahe)\n","        fundus_caps_after_l.append(\"Left clahe\")\n","        l_vessel = create_vessel(left_img)\n","        fundus_imgs_after_l.append(l_vessel)\n","        fundus_caps_after_l.append(\"Left vessel\")\n","        st.image(fundus_imgs_after_l, caption=fundus_caps_after_l, width=330, channels='BGR')\n","\n","        model_input_holder['left'] = cooker([l_clahe, l_vessel])\n","\n","    '## Process right fundus image'\n","    if right_fundus:\n","        r_clahe = create_clahe(right_img)\n","        fundus_imgs_after_r.append(r_clahe)\n","        fundus_caps_after_r.append(\"Right clahe\")\n","        r_vessel = create_vessel(right_img)\n","        fundus_imgs_after_r.append(r_vessel)\n","        fundus_caps_after_r.append(\"Right vessel\")\n","        st.image(fundus_imgs_after_r, caption=fundus_caps_after_r, width=330, channels='BGR')\n","\n","        model_input_holder['right'] = cooker([r_clahe, r_vessel])\n","    \n","    \"## Result\"\n","    if left_fundus:\n","        y_p = predict(x_model, *model_input_holder['left'], device=device)\n","    elif right_fundus:\n","        y_p = predict(x_model, *model_input_holder['right'], device=device)\n","    else:\n","        y_p = predict(x_model, *model_input_holder['left'], *model_input_holder['right'], device=device)\n","\n","    plt.barh(labels, y_p)\n","    st.pyplot()\n","'''\n","\n","with open(\"life_vest.py\", 'w') as f:\n","  f.write(code)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UgOgFVyLnAu4","colab_type":"text"},"source":["# Do do do"]},{"cell_type":"code","metadata":{"id":"wjNXf4R0k6Sk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597889179456,"user_tz":-420,"elapsed":61874,"user":{"displayName":"Oanh Pham","photoUrl":"","userId":"07064024230159202916"}},"outputId":"d0d9bbec-9298-4c25-c126-926ebf28d67a"},"source":["!cp ngrok ngrrrok\n","!pkill ngrrrok\n","get_ipython().system_raw('./ngrrrok http 8501 &')\n","! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print('Open this link in your browser:', json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Open this link in your browser: https://ba3e66090ea0.ngrok.io\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AyzUPGIjbIFy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597891659410,"user_tz":-420,"elapsed":2541433,"user":{"displayName":"Oanh Pham","photoUrl":"","userId":"07064024230159202916"}},"outputId":"c62b27d1-544f-483a-fc76-04680d3bc8dd"},"source":["!streamlit run life_vest.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.205.67.9:8501\u001b[0m\n","\u001b[0m\n","2020-08-20 02:06:28.819854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-08-20 02:06:30.451407: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n","2020-08-20 02:06:30.512703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:30.513501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n","coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n","2020-08-20 02:06:30.513565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-08-20 02:06:30.771244: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-08-20 02:06:30.903573: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-08-20 02:06:30.930272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-08-20 02:06:31.224880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-08-20 02:06:31.273426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-08-20 02:06:31.803496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-08-20 02:06:31.803811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:31.804725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:31.805486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-08-20 02:06:31.833404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n","2020-08-20 02:06:31.833660: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x589aa80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-08-20 02:06:31.833696: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-08-20 02:06:31.967544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:31.968407: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9747180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-08-20 02:06:31.968442: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2020-08-20 02:06:31.969647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:31.970403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n","coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n","2020-08-20 02:06:31.970497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-08-20 02:06:31.970584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n","2020-08-20 02:06:31.970705: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n","2020-08-20 02:06:31.970766: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n","2020-08-20 02:06:31.970822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n","2020-08-20 02:06:31.970888: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n","2020-08-20 02:06:31.970960: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-08-20 02:06:31.971213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:31.972019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:31.972718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n","2020-08-20 02:06:31.977573: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","2020-08-20 02:06:43.701636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-08-20 02:06:43.701703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n","2020-08-20 02:06:43.701724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n","2020-08-20 02:06:43.708930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:43.709882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-08-20 02:06:43.710638: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-08-20 02:06:43.710697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10350 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b3-5fb5a3c3.pth\n","100% 47.1M/47.1M [00:01<00:00, 26.1MB/s]\n","Loaded pretrained weights for efficientnet-b3\n","Loaded pretrained weights for efficientnet-b3\n","Loaded weights from ./model/clahe.pth\n","Loaded weights from ./model/vessel.pth\n","Loaded weights from ./model/final.pth\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n","2020-08-20 02:15:20.622355: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n","2020-08-20 02:15:24.769143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n"," 1/29 [>.............................] - ETA: 0s2020-08-20 02:15:26.838 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_predict_batch_end` time: 0.0722s). Check your callbacks.\n","29/29 [==============================] - 2s 84ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:15:29.852 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0058s vs `on_predict_batch_end` time: 0.0688s). Check your callbacks.\n","29/29 [==============================] - 2s 76ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","image/png\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:16:35.388 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0059s vs `on_predict_batch_end` time: 0.0972s). Check your callbacks.\n","29/29 [==============================] - 2s 80ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:16:38.271 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_predict_batch_end` time: 0.0724s). Check your callbacks.\n","29/29 [==============================] - 2s 77ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","image/png\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:17:21.102 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_predict_batch_end` time: 0.0976s). Check your callbacks.\n","29/29 [==============================] - 2s 81ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:17:23.762 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0056s vs `on_predict_batch_end` time: 0.0729s). Check your callbacks.\n","29/29 [==============================] - 2s 77ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","image/png\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:18:02.409 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0055s vs `on_predict_batch_end` time: 0.0972s). Check your callbacks.\n","29/29 [==============================] - 2s 80ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:18:05.222 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0065s vs `on_predict_batch_end` time: 0.0730s). Check your callbacks.\n","29/29 [==============================] - 2s 77ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","image/png\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:18:59.849 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_predict_batch_end` time: 0.0905s). Check your callbacks.\n","29/29 [==============================] - 2s 79ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:19:03.054 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0071s vs `on_predict_batch_end` time: 0.0719s). Check your callbacks.\n","29/29 [==============================] - 2s 77ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","image/png\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:20:13.258 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_predict_batch_end` time: 0.0965s). Check your callbacks.\n","29/29 [==============================] - 2s 80ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:20:15.992 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_predict_batch_end` time: 0.0696s). Check your callbacks.\n","29/29 [==============================] - 2s 76ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","image/png\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:20:55.965 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_predict_batch_end` time: 0.0975s). Check your callbacks.\n","29/29 [==============================] - 2s 81ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:20:58.851 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0077s vs `on_predict_batch_end` time: 0.0709s). Check your callbacks.\n","29/29 [==============================] - 2s 77ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","image/png\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:21:33.159 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0068s vs `on_predict_batch_end` time: 0.0881s). Check your callbacks.\n","29/29 [==============================] - 2s 79ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","clahe: (240, 240, 3)\n","new full images shape: \n","(1, 241, 241, 1)\n"," 2/29 [=>............................] - ETA: 1s2020-08-20 02:21:35.904 Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_predict_batch_end` time: 0.0736s). Check your callbacks.\n","29/29 [==============================] - 2s 77ms/step\n","N_patches_h: 30\n","N_patches_w: 30\n","N_patches_img: 900\n","According to the dimension inserted, there are 1 full images (of 241x241 each)\n","900 900\n","using avg\n","(240, 240, 1)\n","image/jpeg\n","image/jpeg\n","image/png\n","\u001b[34m  Stopping...\u001b[0m\n","\u001b[34m  Stopping...\u001b[0m\n"],"name":"stdout"}]}]}